{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "import sys\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Reshape, Permute\n",
    "from keras.layers.convolutional import Convolution2D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "\n",
    "TH_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.3/music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5'\n",
    "\n",
    "def librosa_exists():\n",
    "    try:\n",
    "        __import__('librosa')\n",
    "    except ImportError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def preprocess_input(audio_path, dim_ordering='default'):\n",
    "    '''Reads an audio file and outputs a Mel-spectrogram.\n",
    "    '''\n",
    "    if dim_ordering == 'default':\n",
    "        dim_ordering = K.image_dim_ordering()\n",
    "    assert dim_ordering in {'tf', 'th'}\n",
    "\n",
    "    if librosa_exists():\n",
    "        import librosa\n",
    "    else:\n",
    "        raise RuntimeError('Librosa is required to process audio files.\\n' +\n",
    "                           'Install it via `pip install librosa` \\nor visit ' +\n",
    "                           'http://librosa.github.io/librosa/ for details.')\n",
    "\n",
    "    # mel-spectrogram parameters\n",
    "    SR = 12000\n",
    "    N_FFT = 512\n",
    "    N_MELS = 96\n",
    "    HOP_LEN = 256\n",
    "\n",
    "    src, sr = librosa.load(audio_path, sr=SR)\n",
    "    n_sample = src.shape[0]\n",
    "\n",
    "    logam = librosa.logamplitude\n",
    "    melgram = librosa.feature.melspectrogram\n",
    "    x = logam(melgram(y=src, sr=SR, hop_length=HOP_LEN,\n",
    "                      n_fft=N_FFT, n_mels=N_MELS) ** 2,\n",
    "              ref_power=1.0)\n",
    "\n",
    "    if dim_ordering == 'th':\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    elif dim_ordering == 'tf':\n",
    "        x = np.expand_dims(x, axis=3)\n",
    "    return x\n",
    "\n",
    "def MusicTaggerCRNN(weights='msd', input_tensor=None,\n",
    "                    include_top=True):\n",
    "    '''Instantiate the MusicTaggerCRNN architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on Million Song Dataset. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "\n",
    "    For preparing mel-spectrogram input, see\n",
    "    `audio_conv_utils.py` in [applications](https://github.com/fchollet/keras/tree/master/keras/applications).\n",
    "    You will need to install [Librosa](http://librosa.github.io/librosa/)\n",
    "    to use it.\n",
    "\n",
    "    # Arguments\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"msd\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        include_top: whether to include the 1 fully-connected\n",
    "            layer (output layer) at the top of the network.\n",
    "            If False, the network outputs 32-dim features.\n",
    "\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    if weights not in {'msd', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `msd` '\n",
    "                         '(pre-training on Million Song Dataset).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (1, 96, 1366)\n",
    "    else:\n",
    "        input_shape = (96, 1366, 1)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        melgram_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            melgram_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            melgram_input = input_tensor\n",
    "\n",
    "    # Determine input axis\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        channel_axis = 1\n",
    "        freq_axis = 2\n",
    "        time_axis = 3\n",
    "    else:\n",
    "        channel_axis = 3\n",
    "        freq_axis = 1\n",
    "        time_axis = 2\n",
    "\n",
    "    # Input block\n",
    "    x = ZeroPadding2D(padding=(0, 37))(melgram_input)\n",
    "    x = BatchNormalization(axis=time_axis, name='bn_0_freq')(x)\n",
    "\n",
    "    # Conv block 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv1')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Conv block 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(3, 3), name='pool2')(x)\n",
    "\n",
    "    # Conv block 3\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool3')(x)\n",
    "\n",
    "    # Conv block 4\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(x)\n",
    "    x = ELU()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4), strides=(4, 4), name='pool4')(x)\n",
    "\n",
    "    # reshaping\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = Permute((3, 1, 2))(x)\n",
    "    x = Reshape((15, 128))(x)\n",
    "\n",
    "    # GRU block 1, 2, output\n",
    "    x = GRU(32, return_sequences=True, name='gru1')(x)\n",
    "    x = GRU(32, return_sequences=False, name='gru2')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dense(50, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(melgram_input, x)\n",
    "    if weights is None:\n",
    "        return model\n",
    "    else:\n",
    "        # Load weights\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_tf_dim_ordering.h5',\n",
    "                                    TF_WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('music_tagger_crnn_weights_tf_kernels_th_dim_ordering.h5',\n",
    "                                    TH_WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            convert_all_kernels_in_model(model)\n",
    "        return model\n",
    "\n",
    "\n",
    "#model = MusicTaggerCRNN(weights='msd')\n",
    "\n",
    "audio_path = '/Users/Chen/百度云同步盘/Startup/Clevo/润华数据/voice2/20170711/207/341432_207_104024.wav'\n",
    "melgram = preprocess_input(audio_path)\n",
    "melgrams = np.expand_dims(melgram, axis=0)\n",
    "\n",
    "#preds = model.predict(melgrams)\n",
    "\n",
    "librosa.get_duration(melgram.squeeze(), sr=12000)\n",
    "\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "librosa.display.specshow(melgram.squeeze(), sr=12000, x_axis='time', y_axis='mel')\n",
    "#plt.imshow(melgram.squeeze(), origin='lower')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
