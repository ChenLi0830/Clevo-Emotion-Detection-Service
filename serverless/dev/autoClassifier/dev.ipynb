{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "''' \n",
    "Classify sounds using database\n",
    "Author: Scott H. Hawley\n",
    "\n",
    "This is kind of a mixture of Keun Woo Choi's code https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "   and the MNIST classifier at https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "Trained using Fraunhofer IDMT's database of monophonic guitar effects, \n",
    "   clips were 2 seconds long, sampled at 44100 Hz\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "from os.path import isfile\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "mono=True\n",
    "\n",
    "\n",
    "def get_class_names(path=\"Preproc/\"):  # class names are subdirectory names in Preproc/ directory\n",
    "    class_names = os.listdir(path)\n",
    "    class_names.remove(\".DS_Store\")\n",
    "    return class_names\n",
    "\n",
    "def get_total_files(path=\"Preproc/\",train_percentage=0.8): \n",
    "    sum_total = 0\n",
    "    sum_train = 0\n",
    "    sum_test = 0\n",
    "    subdirs = os.listdir(path)\n",
    "    subdirs.remove(\".DS_Store\")\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        files = os.listdir(path+subdir)\n",
    "        # files.remove(\".DS_Store\")\n",
    "        n_files = len(files)\n",
    "        sum_total += n_files\n",
    "        n_train = int(train_percentage*n_files)\n",
    "        n_test = n_files - n_train\n",
    "        sum_train += n_train\n",
    "        sum_test += n_test\n",
    "    return sum_total, sum_train, sum_test\n",
    "\n",
    "def get_sample_dimensions(path='Preproc/'):\n",
    "    classnames = os.listdir(path)\n",
    "    classnames.remove(\".DS_Store\")\n",
    "    classname = classnames[0]\n",
    "    files = os.listdir(path+classname)\n",
    "    # files.remove(\".DS_Store\")\n",
    "    infilename = files[0]\n",
    "    audio_path = path + classname + '/' + infilename\n",
    "    melgram = np.load(audio_path)\n",
    "    print(\"   get_sample_dimensions: melgram.shape = \",melgram.shape)\n",
    "    return melgram.shape\n",
    " \n",
    "\n",
    "def encode_class(class_name, class_names):  # makes a \"one-hot\" vector for each class name called\n",
    "    try:\n",
    "        idx = class_names.index(class_name)\n",
    "        vec = np.zeros(len(class_names))\n",
    "        vec[idx] = 1\n",
    "        return vec\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def shuffle_XY_paths(X,Y,paths):   # generates a randomized order, keeping X&Y(&paths) together\n",
    "    assert (X.shape[0] == Y.shape[0] )\n",
    "    idx = np.array(range(Y.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    newX = np.copy(X)\n",
    "    newY = np.copy(Y)\n",
    "    newpaths = paths\n",
    "    for i in range(len(idx)):\n",
    "        newX[i] = X[idx[i],:,:]\n",
    "        newY[i] = Y[idx[i],:]\n",
    "        newpaths[i] = paths[idx[i]]\n",
    "    return newX, newY, newpaths\n",
    "\n",
    "\n",
    "'''\n",
    "So we make the training & testing datasets here, and we do it separately.\n",
    "Why not just make one big dataset, shuffle, and then split into train & test?\n",
    "because we want to make sure statistics in training & testing are as similar as possible\n",
    "'''\n",
    "def build_datasets(train_percentage=0.8, preproc=False):\n",
    "    if (preproc):\n",
    "        path = \"Preproc/\"\n",
    "    else:\n",
    "        path = \"Samples/\"\n",
    "\n",
    "    class_names = get_class_names(path=path)\n",
    "    print(\"class_names = \",class_names)\n",
    "\n",
    "    total_files, total_train, total_test = get_total_files(path=path, train_percentage=train_percentage)\n",
    "    print(\"total files = \",total_files)\n",
    "\n",
    "    nb_classes = len(class_names)\n",
    "\n",
    "    # pre-allocate memory for speed (old method used np.concatenate, slow)\n",
    "    mel_dims = get_sample_dimensions(path=path)  # Find out the 'shape' of each data file\n",
    "    X_train = np.zeros((total_train, mel_dims[1], mel_dims[2], mel_dims[3]))   \n",
    "    Y_train = np.zeros((total_train, nb_classes))  \n",
    "    X_test = np.zeros((total_test, mel_dims[1], mel_dims[2], mel_dims[3]))  \n",
    "    Y_test = np.zeros((total_test, nb_classes))  \n",
    "    paths_train = []\n",
    "    paths_test = []\n",
    "\n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    for idx, classname in enumerate(class_names):\n",
    "        this_Y = np.array(encode_class(classname,class_names) )\n",
    "        this_Y = this_Y[np.newaxis,:]\n",
    "        class_files = os.listdir(path+classname)\n",
    "        # class_files.remove(\".DS_Store\")\n",
    "        n_files = len(class_files)\n",
    "        n_load =  n_files\n",
    "        n_train = int(train_percentage * n_load)\n",
    "        printevery = 100\n",
    "        print(\"\")\n",
    "        for idx2, infilename in enumerate(class_files[0:n_load]):          \n",
    "            audio_path = path + classname + '/' + infilename\n",
    "            if (0 == idx2 % printevery):\n",
    "                print('\\r Loading class: {:14s} ({:2d} of {:2d} classes)'.format(classname,idx+1,nb_classes),\n",
    "                       \", file \",idx2+1,\" of \",n_load,\": \",audio_path,sep=\"\")\n",
    "            #start = timer()\n",
    "            if (preproc):\n",
    "              melgram = np.load(audio_path)\n",
    "              sr = 44100\n",
    "            else:\n",
    "              aud, sr = librosa.load(audio_path, mono=mono,sr=None)\n",
    "              melgram = librosa.logamplitude(librosa.feature.melspectrogram(aud, sr=sr, n_mels=96),ref_power=1.0)[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "            melgram = melgram[:,:,:,0:mel_dims[3]]   # just in case files are differnt sizes: clip to first file size\n",
    "       \n",
    "            #end = timer()\n",
    "            #print(\"time = \",end - start) \n",
    "            if (idx2 < n_train):\n",
    "                # concatenate is SLOW for big datasets; use pre-allocated instead\n",
    "                #X_train = np.concatenate((X_train, melgram), axis=0)  \n",
    "                #Y_train = np.concatenate((Y_train, this_Y), axis=0)\n",
    "                X_train[train_count,:,:] = melgram\n",
    "                Y_train[train_count,:] = this_Y\n",
    "                paths_train.append(audio_path)     # list-appending is still fast. (??)\n",
    "                train_count += 1\n",
    "            else:\n",
    "                X_test[test_count,:,:] = melgram\n",
    "                Y_test[test_count,:] = this_Y\n",
    "                #X_test = np.concatenate((X_test, melgram), axis=0)\n",
    "                #Y_test = np.concatenate((Y_test, this_Y), axis=0)\n",
    "                paths_test.append(audio_path)\n",
    "                test_count += 1\n",
    "        print(\"\")\n",
    "\n",
    "    print(\"Shuffling order of data...\")\n",
    "    X_train, Y_train, paths_train = shuffle_XY_paths(X_train, Y_train, paths_train)\n",
    "    X_test, Y_test, paths_test = shuffle_XY_paths(X_test, Y_test, paths_test)\n",
    "\n",
    "    return X_train, Y_train, paths_train, X_test, Y_test, paths_test, class_names, sr\n",
    "\n",
    "\n",
    "\n",
    "def build_model(X,Y,nb_classes):\n",
    "    nb_filters = 32  # number of convolutional filters to use\n",
    "    pool_size = (2, 2)  # size of pooling area for max pooling\n",
    "    kernel_size = (3, 3)  # convolution kernel size\n",
    "    nb_layers = 4\n",
    "#     input_shape = (1, X.shape[2], X.shape[3])\n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(BatchNormalization(axis=1, mode=2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    for layer in range(nb_layers-1):\n",
    "        model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n",
    "#         model.add(BatchNormalization(axis=1, mode=2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ELU(alpha=1.0))  \n",
    "        model.add(MaxPooling2D(pool_size=pool_size))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names =  ['Creative, Passionate', 'Criticism, Cynicism', 'Defensivness, Anxiety', 'Friendly, Warm', 'Hostility, Anger', 'Leadership, Charisma', 'Loneliness, Unfulfillment', 'Love, Happiness', 'Sadness, Sorrow', 'Self-Control, Practicality', 'Supremacy, Arrogance', 'Unknown']\n",
      "total files =  904\n",
      "   get_sample_dimensions: melgram.shape =  (1, 1, 96, 157)\n",
      "\n",
      " Loading class: Creative, Passionate ( 1 of 12 classes), file 1 of 65: Preproc/Creative, Passionate/334482_206_082351__1.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Criticism, Cynicism ( 2 of 12 classes), file 1 of 37: Preproc/Criticism, Cynicism/334486_209_085450__17.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Defensivness, Anxiety ( 3 of 12 classes), file 1 of 20: Preproc/Defensivness, Anxiety/334485_211_084904__4.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Friendly, Warm ( 4 of 12 classes), file 1 of 21: Preproc/Friendly, Warm/334486_209_085450__43.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Hostility, Anger ( 5 of 12 classes), file 1 of 248: Preproc/Hostility, Anger/334482_206_082351__7.wav.npy\n",
      " Loading class: Hostility, Anger ( 5 of 12 classes), file 101 of 248: Preproc/Hostility, Anger/334498_209_095454__32.wav.npy\n",
      " Loading class: Hostility, Anger ( 5 of 12 classes), file 201 of 248: Preproc/Hostility, Anger/334562_209_093608__3.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Leadership, Charisma ( 6 of 12 classes), file 1 of 78: Preproc/Leadership, Charisma/334482_206_082351__6.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Loneliness, Unfulfillment ( 7 of 12 classes), file 1 of 15: Preproc/Loneliness, Unfulfillment/334492_208_091829__2.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Love, Happiness ( 8 of 12 classes), file 1 of 24: Preproc/Love, Happiness/334490_209_091532__3.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Sadness, Sorrow ( 9 of 12 classes), file 1 of 22: Preproc/Sadness, Sorrow/334491_208_091642__3.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Self-Control, Practicality (10 of 12 classes), file 1 of 17: Preproc/Self-Control, Practicality/334482_206_082351__4.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Supremacy, Arrogance (11 of 12 classes), file 1 of 265: Preproc/Supremacy, Arrogance/334482_206_082351__0.wav.npy\n",
      " Loading class: Supremacy, Arrogance (11 of 12 classes), file 101 of 265: Preproc/Supremacy, Arrogance/334498_209_095454__177.wav.npy\n",
      " Loading class: Supremacy, Arrogance (11 of 12 classes), file 201 of 265: Preproc/Supremacy, Arrogance/334536_208_162145__9.wav.npy\n",
      "\n",
      "\n",
      " Loading class: Unknown        (12 of 12 classes), file 1 of 92: Preproc/Unknown/334485_211_084904__3.wav.npy\n",
      "\n",
      "Shuffling order of data...\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# get the data\n",
    "X_train, Y_train, paths_train, X_test, Y_test, paths_test, class_names, sr = build_datasets(preproc=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 96, 157, 1)\n",
      "(719, 12)\n",
      "(185, 96, 157, 1)\n",
      "(185, 12)\n",
      "['Creative, Passionate', 'Criticism, Cynicism', 'Defensivness, Anxiety', 'Friendly, Warm', 'Hostility, Anger', 'Leadership, Charisma', 'Loneliness, Unfulfillment', 'Love, Happiness', 'Sadness, Sorrow', 'Self-Control, Practicality', 'Supremacy, Arrogance', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12616e0f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAAD8CAYAAAA4w4cyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8dtXCr6rDeS72kC+qw3ku1IH9D/F2BcQRTU0yQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11549b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(X_train[0,0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 157, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape\n",
    "# X_train[0].reshape(1, 96, 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 96, 157, 1)\n",
      "(719, 12)\n",
      "(185, 96, 157, 1)\n",
      "(185, 12)\n",
      "['Creative, Passionate', 'Criticism, Cynicism', 'Defensivness, Anxiety', 'Friendly, Warm', 'Hostility, Anger', 'Leadership, Charisma', 'Loneliness, Unfulfillment', 'Love, Happiness', 'Sadness, Sorrow', 'Self-Control, Practicality', 'Supremacy, Arrogance', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "img_rows = 96\n",
    "img_cols = 157\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chen/anaconda/envs/clevo_py3/lib/python3.5/site-packages/ipykernel_launcher.py:187: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(96, 157, ..., padding=\"valid\")`\n",
      "/Users/Chen/anaconda/envs/clevo_py3/lib/python3.5/site-packages/ipykernel_launcher.py:193: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "# make the model\n",
    "model = build_model(X_train,Y_train, nb_classes=len(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 94, 155, 32)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 94, 155, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 94, 155, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 92, 153, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 92, 153, 32)       128       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 92, 153, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 46, 76, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 46, 76, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 44, 74, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 44, 74, 32)        128       \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 44, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 22, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 20, 35, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 35, 32)        128       \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 20, 35, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5440)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               696448    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 726,572\n",
      "Trainable params: 726,316\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adadelta',\n",
    "          metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for previous weights...\n",
      "No checkpoint file detected.  Starting from scratch.\n",
      "Train on 719 samples, validate on 185 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chen/anaconda/envs/clevo_py3/lib/python3.5/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/719 [=========================>....] - ETA: 5s - loss: 3.7146 - acc: 0.1891 Epoch 00000: val_loss improved from inf to 2.30282, saving model to weights.hdf5\n",
      "719/719 [==============================] - 59s - loss: 3.5473 - acc: 0.1989 - val_loss: 2.3028 - val_acc: 0.1730\n",
      "Epoch 2/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.3400 - acc: 0.2344 Epoch 00001: val_loss improved from 2.30282 to 2.14415, saving model to weights.hdf5\n",
      "719/719 [==============================] - 61s - loss: 2.3440 - acc: 0.2378 - val_loss: 2.1441 - val_acc: 0.2703\n",
      "Epoch 3/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.2261 - acc: 0.2859 Epoch 00002: val_loss improved from 2.14415 to 2.13939, saving model to weights.hdf5\n",
      "719/719 [==============================] - 64s - loss: 2.2179 - acc: 0.2823 - val_loss: 2.1394 - val_acc: 0.2270\n",
      "Epoch 4/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.2301 - acc: 0.2641 Epoch 00003: val_loss improved from 2.13939 to 2.10625, saving model to weights.hdf5\n",
      "719/719 [==============================] - 68s - loss: 2.2249 - acc: 0.2643 - val_loss: 2.1062 - val_acc: 0.2757\n",
      "Epoch 5/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.2296 - acc: 0.2422 Epoch 00004: val_loss did not improve\n",
      "719/719 [==============================] - 70s - loss: 2.2258 - acc: 0.2378 - val_loss: 2.1111 - val_acc: 0.2757\n",
      "Epoch 6/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 2.1911 - acc: 0.2594 Epoch 00005: val_loss did not improve\n",
      "719/719 [==============================] - 76s - loss: 2.1754 - acc: 0.2656 - val_loss: 2.1462 - val_acc: 0.2703\n",
      "Epoch 7/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.1422 - acc: 0.2687 Epoch 00006: val_loss did not improve\n",
      "719/719 [==============================] - 66s - loss: 2.1425 - acc: 0.2601 - val_loss: 2.1249 - val_acc: 0.2649\n",
      "Epoch 8/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 2.1293 - acc: 0.2859 Epoch 00007: val_loss improved from 2.10625 to 2.08200, saving model to weights.hdf5\n",
      "719/719 [==============================] - 76s - loss: 2.1304 - acc: 0.2740 - val_loss: 2.0820 - val_acc: 0.2865\n",
      "Epoch 9/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.1038 - acc: 0.2609 Epoch 00008: val_loss did not improve\n",
      "719/719 [==============================] - 61s - loss: 2.1059 - acc: 0.2643 - val_loss: 2.1281 - val_acc: 0.2811\n",
      "Epoch 10/100\n",
      "640/719 [=========================>....] - ETA: 5s - loss: 2.1205 - acc: 0.2797 Epoch 00009: val_loss did not improve\n",
      "719/719 [==============================] - 60s - loss: 2.1113 - acc: 0.2865 - val_loss: 2.2390 - val_acc: 0.2757\n",
      "Epoch 11/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.1070 - acc: 0.2844 Epoch 00010: val_loss improved from 2.08200 to 2.05679, saving model to weights.hdf5\n",
      "719/719 [==============================] - 63s - loss: 2.1335 - acc: 0.2851 - val_loss: 2.0568 - val_acc: 0.2324\n",
      "Epoch 12/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.0454 - acc: 0.2828 Epoch 00011: val_loss did not improve\n",
      "719/719 [==============================] - 66s - loss: 2.0608 - acc: 0.2740 - val_loss: 2.1016 - val_acc: 0.2973\n",
      "Epoch 13/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.0990 - acc: 0.2797 Epoch 00012: val_loss did not improve\n",
      "719/719 [==============================] - 60s - loss: 2.1001 - acc: 0.2740 - val_loss: 2.1010 - val_acc: 0.2811\n",
      "Epoch 14/100\n",
      "640/719 [=========================>....] - ETA: 5s - loss: 2.1011 - acc: 0.2641 Epoch 00013: val_loss did not improve\n",
      "719/719 [==============================] - 60s - loss: 2.0861 - acc: 0.2809 - val_loss: 2.1272 - val_acc: 0.2973\n",
      "Epoch 15/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.1182 - acc: 0.2703 Epoch 00014: val_loss did not improve\n",
      "719/719 [==============================] - 63s - loss: 2.1067 - acc: 0.2782 - val_loss: 2.0920 - val_acc: 0.2811\n",
      "Epoch 16/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.0488 - acc: 0.3141 Epoch 00015: val_loss did not improve\n",
      "719/719 [==============================] - 66s - loss: 2.0359 - acc: 0.3129 - val_loss: 2.1049 - val_acc: 0.2919\n",
      "Epoch 17/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 2.0332 - acc: 0.3109 Epoch 00016: val_loss did not improve\n",
      "719/719 [==============================] - 65s - loss: 2.0181 - acc: 0.3143 - val_loss: 2.1161 - val_acc: 0.2757\n",
      "Epoch 18/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9786 - acc: 0.3000 Epoch 00017: val_loss did not improve\n",
      "719/719 [==============================] - 66s - loss: 1.9985 - acc: 0.2976 - val_loss: 2.0960 - val_acc: 0.2919\n",
      "Epoch 19/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9730 - acc: 0.3094 Epoch 00018: val_loss did not improve\n",
      "719/719 [==============================] - 61s - loss: 1.9624 - acc: 0.3171 - val_loss: 2.1651 - val_acc: 0.2973\n",
      "Epoch 20/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9533 - acc: 0.2875 Epoch 00019: val_loss did not improve\n",
      "719/719 [==============================] - 63s - loss: 1.9596 - acc: 0.2879 - val_loss: 2.1620 - val_acc: 0.2865\n",
      "Epoch 21/100\n",
      "640/719 [=========================>....] - ETA: 5s - loss: 1.9428 - acc: 0.3031 Epoch 00020: val_loss did not improve\n",
      "719/719 [==============================] - 59s - loss: 1.9355 - acc: 0.3115 - val_loss: 2.3307 - val_acc: 0.2919\n",
      "Epoch 22/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9943 - acc: 0.2859 Epoch 00021: val_loss did not improve\n",
      "719/719 [==============================] - 61s - loss: 1.9777 - acc: 0.3032 - val_loss: 2.2279 - val_acc: 0.2811\n",
      "Epoch 23/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9418 - acc: 0.3125 Epoch 00022: val_loss did not improve\n",
      "719/719 [==============================] - 61s - loss: 1.9544 - acc: 0.3060 - val_loss: 2.1671 - val_acc: 0.2865\n",
      "Epoch 24/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9346 - acc: 0.3078 Epoch 00023: val_loss did not improve\n",
      "719/719 [==============================] - 62s - loss: 1.9446 - acc: 0.3074 - val_loss: 2.1298 - val_acc: 0.2865\n",
      "Epoch 25/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9410 - acc: 0.3047 Epoch 00024: val_loss did not improve\n",
      "719/719 [==============================] - 65s - loss: 1.9332 - acc: 0.3032 - val_loss: 2.2347 - val_acc: 0.2919\n",
      "Epoch 26/100\n",
      "640/719 [=========================>....] - ETA: 6s - loss: 1.9154 - acc: 0.3219 Epoch 00025: val_loss did not improve\n",
      "719/719 [==============================] - 69s - loss: 1.9162 - acc: 0.3227 - val_loss: 2.1446 - val_acc: 0.3027\n",
      "Epoch 27/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 1.8805 - acc: 0.3469 Epoch 00026: val_loss did not improve\n",
      "719/719 [==============================] - 74s - loss: 1.8919 - acc: 0.3394 - val_loss: 2.1206 - val_acc: 0.2811\n",
      "Epoch 28/100\n",
      "640/719 [=========================>....] - ETA: 10s - loss: 1.8775 - acc: 0.3344Epoch 00027: val_loss did not improve\n",
      "719/719 [==============================] - 103s - loss: 1.8733 - acc: 0.3352 - val_loss: 2.1120 - val_acc: 0.2973\n",
      "Epoch 29/100\n",
      "640/719 [=========================>....] - ETA: 9s - loss: 1.8603 - acc: 0.3203 Epoch 00028: val_loss did not improve\n",
      "719/719 [==============================] - 92s - loss: 1.8848 - acc: 0.3185 - val_loss: 2.1379 - val_acc: 0.2919\n",
      "Epoch 30/100\n",
      "640/719 [=========================>....] - ETA: 8s - loss: 1.8865 - acc: 0.3172 Epoch 00029: val_loss did not improve\n",
      "719/719 [==============================] - 88s - loss: 1.8796 - acc: 0.3213 - val_loss: 2.1798 - val_acc: 0.2541\n",
      "Epoch 31/100\n",
      "640/719 [=========================>....] - ETA: 8s - loss: 1.8716 - acc: 0.3500 Epoch 00030: val_loss did not improve\n",
      "719/719 [==============================] - 91s - loss: 1.8591 - acc: 0.3547 - val_loss: 2.2601 - val_acc: 0.2811\n",
      "Epoch 32/100\n",
      "640/719 [=========================>....] - ETA: 9s - loss: 1.8468 - acc: 0.3375 Epoch 00031: val_loss did not improve\n",
      "719/719 [==============================] - 90s - loss: 1.8276 - acc: 0.3394 - val_loss: 2.1813 - val_acc: 0.2865\n",
      "Epoch 33/100\n",
      "640/719 [=========================>....] - ETA: 8s - loss: 1.8438 - acc: 0.3344 Epoch 00032: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719/719 [==============================] - 85s - loss: 1.8262 - acc: 0.3408 - val_loss: 2.2469 - val_acc: 0.3081\n",
      "Epoch 34/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 1.8090 - acc: 0.3500 Epoch 00033: val_loss did not improve\n",
      "719/719 [==============================] - 78s - loss: 1.8114 - acc: 0.3463 - val_loss: 2.0971 - val_acc: 0.2973\n",
      "Epoch 35/100\n",
      "640/719 [=========================>....] - ETA: 8s - loss: 1.8415 - acc: 0.3297 Epoch 00034: val_loss did not improve\n",
      "719/719 [==============================] - 81s - loss: 1.8387 - acc: 0.3241 - val_loss: 2.0793 - val_acc: 0.2919\n",
      "Epoch 36/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 1.7852 - acc: 0.3609 Epoch 00035: val_loss did not improve\n",
      "719/719 [==============================] - 87s - loss: 1.7778 - acc: 0.3533 - val_loss: 2.0809 - val_acc: 0.2973\n",
      "Epoch 37/100\n",
      "640/719 [=========================>....] - ETA: 8s - loss: 1.7518 - acc: 0.3953 Epoch 00036: val_loss did not improve\n",
      "719/719 [==============================] - 89s - loss: 1.7545 - acc: 0.3853 - val_loss: 2.1070 - val_acc: 0.2973\n",
      "Epoch 38/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 1.7869 - acc: 0.3672 Epoch 00037: val_loss did not improve\n",
      "719/719 [==============================] - 76s - loss: 1.7733 - acc: 0.3658 - val_loss: 2.1569 - val_acc: 0.2595\n",
      "Epoch 39/100\n",
      "640/719 [=========================>....] - ETA: 7s - loss: 1.7230 - acc: 0.3594 Epoch 00038: val_loss did not improve\n",
      "719/719 [==============================] - 75s - loss: 1.7319 - acc: 0.3644 - val_loss: 2.1123 - val_acc: 0.2486\n",
      "Epoch 40/100\n",
      "384/719 [===============>..............] - ETA: 28s - loss: 1.6883 - acc: 0.3490"
     ]
    }
   ],
   "source": [
    "# Initialize weights using checkpoint if it exists. (Checkpointing requires h5py)\n",
    "load_checkpoint = True\n",
    "checkpoint_filepath = 'weights.hdf5'\n",
    "if (load_checkpoint):\n",
    "    print(\"Looking for previous weights...\")\n",
    "    if ( isfile(checkpoint_filepath) ):\n",
    "        print ('Checkpoint file detected. Loading weights.')\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "    else:\n",
    "        print ('No checkpoint file detected.  Starting from scratch.')\n",
    "else:\n",
    "    print('Starting from scratch (no checkpoint)')\n",
    "checkpointer = ModelCheckpoint(filepath=checkpoint_filepath, verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "# train and score the model\n",
    "batch_size = 128\n",
    "nb_epoch = 100\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "      verbose=1, validation_data=(X_test, Y_test), callbacks=[checkpointer])\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
